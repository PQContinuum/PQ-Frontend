# ğŸ§  Sistema de Memoria Compartida entre Conversaciones

## ğŸ“– DescripciÃ³n

Este sistema permite que el AI recuerde informaciÃ³n importante del usuario a travÃ©s de **todas sus conversaciones**, no solo dentro de un chat individual.

**Ejemplo:**
- Chat 1: "Mi nombre es Rafael y estoy construyendo un e-commerce con Next.js"
- Chat 2 (NUEVO): "Â¿CÃ³mo optimizo mi app?"
- AI responde: "Rafael, para optimizar tu e-commerce en Next.js..."

El AI recuerda tu nombre y proyecto **sin que lo repitas**.

---

## ğŸ—ï¸ Arquitectura

### Componentes Principales

1. **Base de Datos** (`db/schema.ts`)
   - Tabla `user_context`: Almacena hechos importantes del usuario
   - CategorÃ­as: personal, technical, preferences, project, decisions

2. **ExtracciÃ³n Inteligente** (`lib/memory/fact-extractor.ts`)
   - Detecta keywords importantes en conversaciones
   - Extrae hechos con GPT-4o-mini (bajo costo)
   - Valida y categoriza automÃ¡ticamente

3. **Cache en Memoria** (`lib/memory/context-cache.ts`)
   - Cache LRU simple sin dependencias
   - TTL de 15 minutos
   - Evita consultas repetidas a DB

4. **LÃ­mites por Plan** (`lib/memory/plan-limits.ts`)
   - Free: 10 hechos, 150 tokens, sin auto-extracciÃ³n
   - Basic: 30 hechos, 300 tokens, auto-extracciÃ³n
   - Professional: 100 hechos, 500 tokens, bÃºsqueda inteligente
   - Enterprise: 500 hechos, 1000 tokens, full features

5. **Orquestador Principal** (`lib/memory/user-context.ts`)
   - Combina cache, DB, y lÃ­mites por plan
   - Formatea contexto para el prompt
   - 3 niveles: minimal, standard, full

---

## ğŸš€ InstalaciÃ³n

### 1. Generar MigraciÃ³n de Base de Datos

```bash
# Generar migraciÃ³n desde el schema actualizado
npm run db:generate

# Aplicar migraciÃ³n a la base de datos
npm run db:push
```

Esto crearÃ¡ la tabla `user_context` y el enum `context_category` en tu base de datos.

### 2. Verificar Variables de Entorno

AsegÃºrate de tener configurado:

```env
OPENAI_API_KEY=sk-...
SUPABASE_URL=postgresql://...
```

### 3. El Sistema Ya EstÃ¡ Activo âœ…

Una vez aplicada la migraciÃ³n, el sistema funciona automÃ¡ticamente:
- âœ… API de chat incluye contexto del usuario
- âœ… ExtracciÃ³n de hechos en background
- âœ… Cache automÃ¡tico
- âœ… LÃ­mites por plan aplicados

---

## ğŸ“Š LÃ­mites por Plan

Ajusta los lÃ­mites en `lib/memory/plan-limits.ts`:

| Plan | Max Hechos | Max Tokens | Auto-ExtracciÃ³n | BÃºsqueda Inteligente |
|------|------------|------------|-----------------|----------------------|
| **Free** | 10 | 150 | âŒ | âŒ |
| **Basic** | 30 | 300 | âœ… | âŒ |
| **Professional** | 100 | 500 | âœ… | âœ… |
| **Enterprise** | 500 | 1000 | âœ… | âœ… |

### CÃ³mo Ajustar LÃ­mites

Edita el archivo `lib/memory/plan-limits.ts`:

```typescript
export const PLAN_LIMITS: Record<PlanName, MemoryPlanLimits> = {
  Free: {
    maxContextItems: 10,        // â† CAMBIAR: MÃ¡ximo hechos
    maxContextTokens: 150,      // â† CAMBIAR: Tokens de contexto
    extractionInterval: 10,     // â† CAMBIAR: Extraer cada N mensajes
    autoExtraction: false,      // â† CAMBIAR: Habilitar auto-extracciÃ³n
    // ...
  },
  // ...
};
```

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Modificar Keywords de ExtracciÃ³n

Edita `lib/memory/fact-extractor.ts`:

```typescript
const IMPORTANT_KEYWORDS = [
  'mi nombre', 'me llamo', 'trabajo en',
  'uso', 'prefiero', 'mi proyecto',
  // â† Agregar mÃ¡s keywords aquÃ­
];
```

### Ajustar Cache

Edita `lib/memory/context-cache.ts`:

```typescript
const userContextCache = new SimpleCache<string>(
  1000,              // â† MÃ¡ximo usuarios en cache
  15 * 60 * 1000     // â† TTL en milisegundos (15 min)
);
```

### Cambiar Nivel de Contexto por Defecto

En `lib/memory/plan-limits.ts`:

```typescript
Professional: {
  defaultContextLevel: 'standard',  // â† Cambiar a 'minimal' o 'full'
  // ...
}
```

---

## ğŸ“ API Endpoints

### POST `/api/conversations/[id]/extract-facts`

Extrae hechos importantes de una conversaciÃ³n.

**Request:**
```bash
POST /api/conversations/abc123/extract-facts
Authorization: Bearer <supabase-token>
```

**Response:**
```json
{
  "success": true,
  "factsExtracted": 3,
  "facts": [
    { "category": "personal", "value": "Nombre: Rafael" },
    { "category": "technical", "value": "Usa Next.js 14" },
    { "category": "project", "value": "Construyendo e-commerce" }
  ]
}
```

**Errores:**
- `401 Unauthorized`: Usuario no autenticado
- `403 Forbidden`: Plan no permite auto-extracciÃ³n
- `404 Not Found`: ConversaciÃ³n no existe

---

## ğŸ§ª Testing

### Probar ExtracciÃ³n Manual

```typescript
// En un API route o script
import { extractFactsFromMessages } from '@/lib/memory/fact-extractor';

const messages = [
  { id: '1', role: 'user', content: 'Mi nombre es Rafael', createdAt: new Date() },
  { id: '2', role: 'assistant', content: 'Mucho gusto, Rafael', createdAt: new Date() },
];

const facts = await extractFactsFromMessages(messages);
console.log(facts);
```

### Probar Contexto de Usuario

```typescript
import { getUserContextForPrompt } from '@/lib/memory/user-context';

const context = await getUserContextForPrompt(
  'user-id-123',
  'Professional',
  'Mensaje actual del usuario'
);

console.log(context);
```

### Verificar Cache

```typescript
import { getCacheStats } from '@/lib/memory/context-cache';

console.log(getCacheStats());
// { size: 42, maxSize: 1000, ttlMinutes: 15 }
```

---

## ğŸ› Troubleshooting

### El contexto no se extrae

**Problema:** No se estÃ¡n guardando hechos.

**Soluciones:**
1. Verificar que el plan tenga `autoExtraction: true`
2. Revisar logs de `/api/conversations/[id]/extract-facts`
3. Verificar que OPENAI_API_KEY estÃ© configurado
4. Revisar que la conversaciÃ³n tenga al menos 3 mensajes del usuario

### El contexto no aparece en las respuestas

**Problema:** El AI no usa el contexto guardado.

**Soluciones:**
1. Verificar que hay hechos en la DB: `SELECT * FROM user_context WHERE user_id = '...'`
2. Invalidar cache: `invalidateUserContext(userId)`
3. Revisar que el prompt incluye el contexto (ver logs de API)

### LÃ­mite de tokens excedido

**Problema:** Error "context too large".

**Soluciones:**
1. Reducir `maxContextTokens` en `plan-limits.ts`
2. Ajustar nivel de contexto a 'minimal' o 'standard'
3. Purgar contexto viejo: `pruneOldestContext(userId, 10)`

---

## ğŸ“ˆ Optimizaciones de Costo

### Reducir Llamadas a OpenAI

```typescript
// En plan-limits.ts
Free: {
  extractionInterval: 15,  // Extraer cada 15 mensajes (en lugar de 10)
  autoExtraction: false,   // Deshabilitar completamente
}
```

### Usar Contexto Minimal para Mensajes Cortos

El sistema ya hace esto automÃ¡ticamente:
- Mensaje < 5 palabras â†’ nivel 'minimal' (~100 tokens)
- Mensaje normal â†’ nivel 'standard' (~300 tokens)
- Mensaje > 50 palabras â†’ nivel 'full' (~500 tokens)

### CompresiÃ³n de Contexto Viejo

Para planes Premium, comprimir contexto automÃ¡ticamente:

```typescript
Professional: {
  autoCompression: true,  // âœ… Habilitar compresiÃ³n
  contextRetentionDays: 90,  // Comprimir despuÃ©s de 90 dÃ­as
}
```

---

## ğŸ” Seguridad y Privacidad

### Datos Sensibles

El sistema automÃ¡ticamente **NO extrae**:
- Passwords
- API keys
- Tokens de acceso
- InformaciÃ³n bancaria

### GDPR / Privacidad

Para cumplir con regulaciones:

```typescript
// Eliminar todo el contexto de un usuario
import { db } from '@/db';
import { userContext } from '@/db/schema';
import { eq } from 'drizzle-orm';

await db.delete(userContext).where(eq(userContext.userId, userId));
```

---

## ğŸ“š Estructura de Archivos

```
lib/memory/
â”œâ”€â”€ README.md                   # Este archivo
â”œâ”€â”€ plan-limits.ts              # LÃ­mites por plan (AJUSTAR AQUÃ)
â”œâ”€â”€ context-cache.ts            # Cache en memoria
â”œâ”€â”€ fact-extractor.ts           # ExtracciÃ³n con GPT-4o-mini
â””â”€â”€ user-context.ts             # Orquestador principal

db/
â”œâ”€â”€ schema.ts                   # Schema de user_context (MIGRAR)
â””â”€â”€ queries/
    â””â”€â”€ user-context.ts         # Queries de DB

app/api/
â”œâ”€â”€ chat/route.ts               # âœ… Incluye contexto en respuestas
â””â”€â”€ conversations/[id]/
    â””â”€â”€ extract-facts/route.ts  # API de extracciÃ³n
```

---

## âœ… Checklist de ImplementaciÃ³n

- [x] Tabla `user_context` creada en DB
- [x] LÃ­mites por plan configurados
- [x] Cache implementado
- [x] ExtracciÃ³n inteligente con keywords
- [x] API de chat incluye contexto
- [x] ExtracciÃ³n en background configurada
- [ ] **Generar y aplicar migraciÃ³n** (`npm run db:generate && npm run db:push`)
- [ ] **Ajustar lÃ­mites por plan** (en `plan-limits.ts`)
- [ ] **Testing en ambiente de desarrollo**
- [ ] **Deploy a producciÃ³n**

---

## ğŸ¯ PrÃ³ximos Pasos

DespuÃ©s de aplicar la migraciÃ³n:

1. **Probar en desarrollo:**
   ```bash
   npm run dev
   # Iniciar un chat y decir "Mi nombre es [tu nombre]"
   # Crear un NUEVO chat y verificar que recuerda tu nombre
   ```

2. **Ajustar lÃ­mites segÃºn tu estrategia:**
   - Editar `lib/memory/plan-limits.ts`
   - Reiniciar servidor

3. **Monitorear costos:**
   - Revisar uso de OpenAI API (extracciÃ³n con gpt-4o-mini)
   - Ajustar `extractionInterval` si es necesario

4. **Opcional: Implementar compresiÃ³n automÃ¡tica**
   - Para planes Enterprise
   - Comprimir contexto viejo con cron job

---

## ğŸ’¡ Tips y Mejores PrÃ¡cticas

1. **Empezar conservador:** Usa lÃ­mites bajos y ajusta segÃºn uso real
2. **Monitorear tamaÃ±o de contexto:** Revisar `user_context` en DB periÃ³dicamente
3. **Cache es tu amigo:** El cache reduce consultas a DB en 90%+
4. **Background extraction:** Nunca bloquear la respuesta del usuario
5. **Plan Free limitado:** Fuerza upgrade con lÃ­mites restrictivos

---

## ğŸ“ Soporte

Si tienes problemas:
1. Revisar logs en consola del servidor
2. Verificar migraciÃ³n aplicada: `SELECT * FROM user_context LIMIT 1;`
3. Verificar plan del usuario: `SELECT plan_name FROM subscriptions WHERE user_id = '...'`
4. Revisar este README completo

---

**Â¡Sistema de Memoria Compartida Listo! ğŸš€**
